# OnDevide MultiModal multi-agent System

<div align="center">

**Multi-Modal Behavioral Fraud Detection System**

[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![React Native](https://img.shields.io/badge/React%20Native-0.79-61DAFB.svg)](https://reactnative.dev/)
[![Expo](https://img.shields.io/badge/Expo-53.0-000020.svg)](https://expo.dev/)

**Real-time fraud detection using behavioral biometrics and AI-powered multi-agent analysis**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Getting Started](#-getting-started) â€¢ [Demo](#-demo) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸ¯ Overview

QuadFusion is an advanced **multi-modal behavioral fraud detection system** that leverages AI and machine learning to identify fraudulent activities through behavioral biometrics. Unlike traditional authentication methods, QuadFusion continuously monitors user behavior patterns across multiple dimensions:

- **Touch Patterns** - Swipe dynamics, tap pressure, gesture recognition
- **Typing Behavior** - Keystroke dynamics, rhythm analysis, timing patterns
- **Voice Authentication** - Speaker identification, voice pattern analysis
- **Visual Biometrics** - Face recognition, scene analysis
- **Motion Analysis** - Accelerometer, gyroscope, magnetometer data
- **App Usage Patterns** - Usage frequency, navigation patterns, temporal analysis

The system uses a **multi-agent architecture** where specialized AI agents analyze different behavioral aspects and a coordinator agent fuses their decisions for robust fraud detection.

---

## âœ¨ Features

### ğŸ”’ **Multi-Modal Authentication**
- Continuous behavioral biometric monitoring
- Real-time anomaly detection
- Risk scoring with confidence levels
- Session-based fraud analysis

### ğŸ¤– **AI-Powered Multi-Agent System**
- **6 Specialized Agents:**
  - Touch Pattern Agent
  - Typing Behavior Agent
  - Voice Command Agent
  - Visual Agent
  - Movement Agent
  - App Usage Agent
- **Coordinator Agent** for intelligent decision fusion
- Lightweight models optimized for mobile deployment

### ğŸ“± **Mobile-First Design**
- React Native + Expo for cross-platform support
- Real-time sensor data collection
- Live monitoring dashboard
- Beautiful, responsive UI with animations
- Offline-capable with local processing

### ğŸ›¡ï¸ **Privacy & Security**
- End-to-end encryption for biometric data
- On-device processing where possible
- Secure data storage and transmission
- GDPR-compliant data handling

### ğŸ“Š **Developer Experience**
- RESTful API with comprehensive documentation
- Easy integration with existing apps
- Detailed logging and monitoring
- Performance metrics and analytics

---

## ğŸ—ï¸ Architecture

### System Components

```
QuadFusion/
â”œâ”€â”€ Backend (Python)          # AI/ML Processing Server
â”‚   â”œâ”€â”€ API Server           # FastAPI REST endpoints
â”‚   â”œâ”€â”€ Multi-Agent System   # 6 specialized + 1 coordinator
â”‚   â”œâ”€â”€ Models               # ML models (LSTM, CNN, etc.)
â”‚   â”œâ”€â”€ Data Pipeline        # Collection, preprocessing, encryption
â”‚   â””â”€â”€ Mobile Deployment    # ONNX/TFLite conversion
â”‚
â””â”€â”€ Frontend (React Native)   # Mobile Application
    â”œâ”€â”€ Sensor Managers      # Data collection
    â”œâ”€â”€ Live Monitoring      # Real-time dashboard
    â”œâ”€â”€ UI Components        # Responsive, animated UI
    â””â”€â”€ API Client           # Backend communication
```

### Multi-Agent Architecture

```
User Interaction Data
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Specialized Agent Layer         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ TouchPatternAgent    (20%)      â”‚
â”‚ â€¢ TypingBehaviorAgent  (15%)      â”‚
â”‚ â€¢ VoiceCommandAgent    (20%)      â”‚
â”‚ â€¢ VisualAgent          (25%)      â”‚
â”‚ â€¢ MovementAgent        (10%)      â”‚
â”‚ â€¢ AppUsageAgent        (10%)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Coordinator Agent               â”‚
â”‚   â€¢ Weighted fusion               â”‚
â”‚   â€¢ Confidence aggregation        â”‚
â”‚   â€¢ Risk level determination      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Fraud Decision
```

### Technology Stack

**Backend:**
- Python 3.10+
- FastAPI (REST API)
- TensorFlow & PyTorch (Deep Learning)
- Scikit-learn (ML algorithms)
- ONNX/TFLite (Mobile optimization)
- Librosa (Audio processing)
- OpenCV & MediaPipe (Computer Vision)

**Frontend:**
- React Native 0.79
- Expo 53.0
- TypeScript
- Expo Sensors, Camera, Audio
- Victory Native (Charts)
- React Navigation

---

## ğŸš€ Getting Started

### Prerequisites

- **Backend:** Python 3.10+, pip
- **Frontend:** Node.js 18+, npm/yarn
- **Mobile:** Expo Go app (for testing) or Expo CLI

### Quick Start

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Samrudhp/OnDevice-Multimodal-Agent.git
cd QuadFusion
```

#### 2ï¸âƒ£ Backend Setup

```bash
cd src/backend/src

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start API server
cd ..
python api_server.py
```

The backend server will start at \`http://127.0.0.1:8000\`

**API Documentation:** Visit \`http://127.0.0.1:8000/docs\` for interactive API docs

#### 3ï¸âƒ£ Frontend Setup

```bash
cd src/qf

# Install dependencies
npm install

# Start development server
npm run dev
```

Scan the QR code with Expo Go app to run on your device.

### Configuration

#### Backend Configuration
Edit \`src/backend/src/config.yaml\`:

```yaml
agents:
  coordinator:
    agent_weights:
      TouchPatternAgent: 0.2
      TypingBehaviorAgent: 0.15
      VoiceCommandAgent: 0.2
      VisualAgent: 0.25
      AppUsageAgent: 0.1
      MovementAgent: 0.1
    risk_thresholds:
      low: 0.3
      medium: 0.6
      high: 0.8
```
---

## ğŸ“– Usage

### Running the Demo

```bash
# Terminal 1: Start backend
cd src/backend
python api_server.py

# Terminal 2: Start frontend
cd src/qf
npm run dev
```

### API Examples

#### Real-time Fraud Detection

```bash
curl -X POST http://127.0.0.1:8000/api/v1/process/realtime \\
  -H "Content-Type: application/json" \\
  -d '{
    "session_id": "session-123",
    "sensor_data": {
      "touch_events": [...],
      "keystroke_events": [...],
      "motion_data": {...},
      "audio_data": "base64...",
      "image_data": "base64..."
    }
  }'
```

**Response:**
```json
{
  "anomaly_score": 0.23,
  "risk_level": "low",
  "confidence": 0.87,
  "agent_results": {
    "MovementAgent": {
      "anomaly_score": 0.15,
      "risk_level": "low",
      "confidence": 0.9
    },
    "TouchPatternAgent": {...},
    ...
  }
}
```

---

## ğŸ¬ Demo

### Live Monitoring Dashboard

The mobile app provides real-time visualization of:
- **Sensor data collection** (touch, motion, audio, camera)
- **Agent analysis results** with individual scores
- **Risk assessment** with confidence levels
- **Processing metrics** and performance stats

### Screenshots

*(Add screenshots of your mobile app here)*

---

## ğŸ“š Documentation

- **[API Specification](src/backend/API_SPECIFICATION.md)** - Complete API reference
- **[Backend Setup](src/backend/START_SERVER.md)** - Detailed backend setup guide
- **[Mobile Setup](src/qf/SETUP_AND_TESTING.md)** - Frontend setup and testing
- **[Model Documentation](src/backend/src/models.md)** - ML model details
- **[Architecture Docs](docs/)** - System architecture and design

---

## ğŸ”§ Development

### Project Structure

```
QuadFusion/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api_server.py              # Main API server
â”‚   â”‚   â”œâ”€â”€ API_SPECIFICATION.md       # API docs
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ agents/                # Multi-agent system
â”‚   â”‚       â”‚   â”œâ”€â”€ coordinator_agent.py
â”‚   â”‚       â”‚   â”œâ”€â”€ touch_pattern_agent.py
â”‚   â”‚       â”‚   â”œâ”€â”€ typing_behavior_agent.py
â”‚   â”‚       â”‚   â”œâ”€â”€ voice_command_agent.py
â”‚   â”‚       â”‚   â”œâ”€â”€ visual_agent.py
â”‚   â”‚       â”‚   â”œâ”€â”€ movement_agent.py
â”‚   â”‚       â”‚   â””â”€â”€ app_usage_agent.py
â”‚   â”‚       â”œâ”€â”€ models/                # ML models
â”‚   â”‚       â”œâ”€â”€ data/                  # Data pipeline
â”‚   â”‚       â”œâ”€â”€ mobile_deployment/     # Model conversion
â”‚   â”‚       â”œâ”€â”€ training/              # Model training
â”‚   â”‚       â””â”€â”€ utils/                 # Utilities
â”‚   â”‚
â”‚   â””â”€â”€ qf/                            # React Native app
â”‚       â”œâ”€â”€ app/                       # Expo Router pages
â”‚       â”œâ”€â”€ components/                # UI components
â”‚       â”œâ”€â”€ lib/                       # Utilities
â”‚       â”‚   â”œâ”€â”€ sensor-manager.ts      # Sensor data collection
â”‚       â”‚   â”œâ”€â”€ api.ts                 # API client
â”‚       â”‚   â””â”€â”€ audio-recorder.ts      # Audio recording
â”‚       â””â”€â”€ config/                    # Configuration
â”‚
â”œâ”€â”€ docs/                              # Documentation
â””â”€â”€ README.md                          # This file
```



## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create your feature branch (\`git checkout -b feature/AmazingFeature\`)
3. Commit your changes (\`git commit -m 'Add some AmazingFeature'\`)
4. Push to the branch (\`git push origin feature/AmazingFeature\`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built for Samsung EnnovateX 2025 AI Challenge
- TensorFlow and PyTorch communities
- Expo and React Native teams
- Open-source ML model contributors

---

## ğŸ“§ Contact

**Project Repository:** [https://github.com/Samrudhp/OnDevice-Multimodal-Agent](https://github.com/Samrudhp/OnDevice-Multimodal-Agent)


---

<div align="center">

**Built with â¤ï¸ using AI and Multi-Agent Systems**

*Protecting users through behavioral intelligence*
