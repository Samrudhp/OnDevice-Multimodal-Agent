# QuadFusion Real Data Verification Guide

This guide shows you exactly what happens when you start monitoring and analyze camera data, with detailed logging to verify real data collection and transmission.

## ğŸ” What to Expect When You Start Monitoring

### 1. **Starting Monitoring Process**
When you tap "Start Monitoring", you'll see these console logs:

```
ğŸš€ Starting monitoring - initializing sensors...
âœ… Motion sensors started
ğŸ¤ Capturing audio sample...
âœ… Audio sample captured: {duration: 1.5, sampleRate: 16000, dataSize: 12345}
ğŸ“· Camera capture would happen here (requires camera integration)
âœ… Monitoring started successfully
```

**Alert Message**: "Monitoring Started - All sensors are now active and collecting data. Interact with your device normally."

### 2. **Real-Time Data Collection**
As you interact with the device, you'll see:

```
ğŸ‘† Touch event captured: down at (540.5, 960.0) pressure=0.80
ğŸ‘† Touch event captured: move at (542.1, 958.3) pressure=0.75
ğŸ‘† Touch event captured: up at (545.0, 955.0) pressure=0.60
âŒ¨ï¸ Keystroke captured: key=65 action=down pressure=0.50
âŒ¨ï¸ Keystroke captured: key=65 action=up pressure=0.45
```

### 3. **Motion Sensor Data**
Motion sensors automatically collect data every 100ms:
- **Accelerometer**: Detects device movement and orientation
- **Gyroscope**: Measures rotation and angular velocity  
- **Magnetometer**: Detects magnetic field changes

### 4. **When You Stop Monitoring**
You'll see detailed data transmission logs:

```
ğŸ”„ Processing collected sensor data...
ğŸ“Š Session ID: live-monitoring-1234567890
ğŸ“¤ Data being sent to API:
  â€¢ Touch events: 15
  â€¢ Keystroke events: 8
  â€¢ Motion data: Available
  â€¢ Audio data: Available (12345 chars)
  â€¢ Image data: Not available
  â€¢ App usage events: 2
  â€¢ Motion details: accel=[0.120, -0.050, 9.810]
ğŸš€ Sending data to backend API...
âœ… Received processing result from API
ğŸ“¥ API Response Summary:
  â€¢ Anomaly score: 0.25
  â€¢ Risk level: low
  â€¢ Confidence: 0.87
  â€¢ Processing time: 145ms
  â€¢ Agents processed: 6
ğŸ¤– Individual Agent Results:
  â€¢ TouchPatternAgent:
    - Anomaly score: 0.20
    - Risk level: low
    - Confidence: 0.90
    - Features: [pressure_variance, swipe_speed, tremor_score]
    - Processing time: 40ms
  â€¢ TypingBehaviorAgent:
    - Anomaly score: 0.15
    - Risk level: low
    - Confidence: 0.85
    - Features: [dwell_times, flight_times, rhythm]
    - Processing time: 30ms
  [... and so on for all 6 agents]
```

**Alert Message**: "Analysis Complete - Risk Level: LOW, Confidence: 87%, Agents: 6"

## ğŸ“· What to Expect When You Analyze Camera

### 1. **Camera Analysis Process**
When you tap "Analyze Face" in the camera tab:

```
ğŸ“· Starting camera analysis...
ğŸ“¸ Capturing image from camera...
âœ… Image captured successfully:
  â€¢ Image size: 45678 characters
  â€¢ Camera facing: front
  â€¢ Image dimensions: 1080x1920
âœ… Image data stored in sensor manager
ğŸš€ Sending image data to API for analysis (Session: camera-capture-1234567890)
ğŸ“¤ Sensor data being sent:
  â€¢ Image data: Available
  â€¢ Camera type: front
  â€¢ Touch events: 3
  â€¢ Motion data: Available
```

### 2. **API Processing Response**
```
âœ… Received analysis result from API:
  â€¢ Overall risk level: low
  â€¢ Confidence: 0.82
  â€¢ Agents processed: 6
ğŸ‘ï¸ Visual Agent Results:
  â€¢ Anomaly score: 0.30
  â€¢ Features analyzed: [face_match, scene_consistency]
  â€¢ Metadata: {face_detected: true, image_data_available: true}
ğŸ“· Camera analysis completed
```

**Alert Message**: "Analysis Complete - Face detected with 82.0% confidence"

### 3. **If Camera Capture Fails**
```
ğŸ“· Camera capture not available, using simulated analysis
ğŸ­ Simulated results: {faceDetected: true, confidence: 75.2, biometricMatch: false}
```

**Alert Message**: "Simulation Mode - Camera capture not available. Using simulated facial analysis."

## ğŸ”§ How to Verify Real Data is Being Sent

### 1. **Check Console Logs**
Open your development console (Metro bundler or browser dev tools) and look for:
- âœ… **Green checkmarks**: Successful operations
- ğŸ“¤ **Upload arrows**: Data being sent to API
- ğŸ“¥ **Download arrows**: Data received from API
- ğŸ¤– **Robot icons**: Agent processing results

### 2. **Verify Network Requests**
In browser dev tools Network tab, look for:
- `POST /api/v1/process/realtime` - Real-time processing requests
- `POST /api/v1/admin/train_all` - Agent initialization
- `GET /api/v1/models/status` - Model status checks

### 3. **Check Backend Logs**
In your backend server console, you should see:
```
INFO - Processing sensor data for session: live-monitoring-1234567890
INFO - TouchPatternAgent processed 15 touch events
INFO - VisualAgent processed image data (45678 chars)
INFO - Returning processing result with 6 agent results
```

## ğŸš¨ Troubleshooting Real Data Issues

### Problem: No Touch Events Captured
**Symptoms**: Console shows `Touch events: 0`
**Solution**: 
- Ensure you're interacting with the screen while monitoring
- Check that touch event handlers are properly attached
- Try scrolling or tapping buttons during monitoring

### Problem: No Motion Data
**Symptoms**: Console shows `Motion data: Not available`
**Solution**:
- Test on a physical device (simulators have limited sensor support)
- Grant motion sensor permissions
- Move the device during monitoring

### Problem: No Audio Data
**Symptoms**: Console shows `Audio data: Not available`
**Solution**:
- Grant microphone permissions
- Ensure device has working microphone
- Check audio recording implementation

### Problem: No Camera Data
**Symptoms**: Console shows `Image data: Not available`
**Solution**:
- Grant camera permissions
- Ensure camera is working
- Try both front and rear cameras
- Test on physical device

### Problem: API Not Receiving Data
**Symptoms**: All data shows as "Available" but API returns empty results
**Solution**:
- Check network connectivity
- Verify backend server is running on correct port
- Check API base URL configuration
- Look for CORS or network errors

## ğŸ“Š Expected Data Volumes

### Typical Monitoring Session (30 seconds):
- **Touch Events**: 10-50 events (depending on interaction)
- **Keystroke Events**: 5-20 events (if typing)
- **Motion Data**: 300+ samples (10Hz sampling rate)
- **Audio Data**: ~24,000 characters (1.5 seconds of audio)
- **Image Data**: 40,000-80,000 characters (if camera used)

### API Response Times:
- **Real-time Processing**: 50-200ms
- **Agent Processing**: 25-70ms per agent
- **Total Response**: Usually under 300ms

## âœ… Verification Checklist

Before considering the system "working correctly":

- [ ] Console shows sensor initialization messages
- [ ] Touch events are logged when interacting with screen
- [ ] Motion data shows real accelerometer values (not all zeros)
- [ ] Audio data is captured and shows realistic size
- [ ] Camera analysis captures real image data
- [ ] API requests are sent with actual sensor data
- [ ] Backend responds with processing results
- [ ] All 6 agents return individual results
- [ ] UI displays analysis results correctly
- [ ] Network tab shows successful API calls
- [ ] Backend logs show data processing

## ğŸ¯ Success Indicators

**You know the system is working correctly when:**

1. **Console logs show real data**: Actual coordinates, sensor values, and data sizes
2. **API calls succeed**: Network requests return 200 status codes
3. **Agent results vary**: Different anomaly scores and confidence levels
4. **Processing times are realistic**: 50-300ms response times
5. **Data sizes make sense**: Audio ~24k chars, images ~50k chars
6. **Alerts show real values**: Actual confidence percentages and risk levels

The enhanced logging system now provides complete visibility into data collection, transmission, and processing, so you can verify that real sensor data is being captured and sent to the API for analysis.